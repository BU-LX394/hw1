{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c04780-68a3-4da5-8c90-108b9be8db13",
   "metadata": {},
   "source": [
    "# HW 1: ChatGPT vs. Wikipedia\n",
    "\n",
    "In this homework assignment, you will study the statistical characteristics of ChatGPT-generated text by conducting a _keyword analysis_ ([Hofland and Johansson, 1989](https://www.abebooks.com/first-edition/Frequency-Analysis-English-Vocabulary-Grammar-Based/32179496983/bd) and others) of a ChatGPT-generated corpus, using an analogous corpus of Wikipedia articles as a reference. When we conduct a keyword analysis, we try to token types (i.e., lexical items) that distinguish a _target text_ from a _reference text_. In class, we saw that \"delve\" was a keyword for ChatGPT-generated text; in this assignment, you will systematically identify other keywords that distinguish [Singh et al.'s (2024)](https://www.sciencedirect.com/science/article/pii/S294971912300047X) ChatGPT corpus from their Wikipedia corpus.\n",
    "\n",
    "## Important: Read Before Starting\n",
    "\n",
    "In the following exercises, you will need to implement (i.e., write code for) functions defined in the `hw1.py` file. **Please write all your code in this file.** You should not submit this notebook with your solutions, and we will not grade it if you do. Please be aware that code written in a Jupyter notebook may run differently when copied into a `.py` file.\n",
    "\n",
    "The outputs shown in this notebook are the outputs that you should get **when all problems have been completed correctly**. You may obtain different results if you attempt to run the code cells before you have completed the problem set, or if you have completed one or more problems incorrectly. **Obtaining the outputs shown in this notebook does not guarantee that your code is correct.**\n",
    "\n",
    "To begin, please run the following import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d76aa21-a002-4777-8707-1c1301db8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.text import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599caa57-fdc7-4ca9-b9c7-fbb0989eab2e",
   "metadata": {},
   "source": [
    "## Problem 1: Python Exercises (8 Points in Total + 1 Point Extra Credit)\n",
    "\n",
    "In these exercises, you will learn and practice Python concepts needed in order to conduct the keyword analysis of the ChatGPT corpus in Problem 2.\n",
    "\n",
    "### Problem 1a: Understand Modules (Written, 1 Point)\n",
    "\n",
    "The file `hw1.py` contains a collection of function definitions, most of which are incomplete. For this assignment, you will _implement_ (i.e., write the code for) the incomplete functions in this file.\n",
    "\n",
    "The code contained in a `.py` file is called a _module_. Modules can be imported, just like packages, by using an `import` statement followed by the module's filename, excluding the `.py` suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950dc87b-a4a8-4d1f-9827-3016840741b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the code for this assignment\n",
    "import hw1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa653c-d669-4d5a-b2a5-eaf4b9a716d4",
   "metadata": {},
   "source": [
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042283a-c2e2-4fda-8c00-cb7e8e4d45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw1.hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c673c-f9e7-4d5f-bb79-487d6eac4209",
   "metadata": {},
   "source": [
    "If you wanted to call the function `foo_bar` defined in the `hw1` module (i.e., the `hw1.py` file), how would you do so?\n",
    "\n",
    "### Problem 1b: Understand Module Reloading (Written, 1 Point)\n",
    "\n",
    "Please edit the function `my_name` in the `hw1` module by replacing the `_` with your name. Once you have done so, please save your changes, and then call the `my_name` function using the code cell below. What happens? Are your changes reflected when the `my_name` function is called again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b20ab1-3654-4bb5-87b3-dba5654928a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "My name is _.\n"
     ]
    }
   ],
   "source": [
    "hw1.my_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b312e82-1b35-4901-a74a-c01e9ce82c83",
   "metadata": {},
   "source": [
    "If you wanted to call the edited version of your `my_name` function from this notebook without restarting it, how would you do so?\n",
    "\n",
    "**Hint:** Please read this [Stack Overflow post](https://stackoverflow.com/questions/1254370/reimport-a-module-while-interactive), and then examine the `import` statements at the top of this notebook.\n",
    "\n",
    "### Problem 1c: Understand Type Hints (Written, 2 Points)\n",
    "\n",
    "The function `add_str` takes two strings, both representing numbers, and returns the two numbers' sum as a string. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3823579e-d9ef-40af-9fcf-7d1f012808e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw1.add_str(\"1\", \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44f286-2cbe-4197-ac92-7f622c149aaf",
   "metadata": {},
   "source": [
    "In the definition for `add_str`, the two parameters `a` and `b` are followed by `: str`, and there is a `-> str` just before the `:`. These pieces of code are called _type hints_. What are type hints? Are they requirements, or just suggestions? What would the definition for the `my_name` function look like if you were to add type hints to it?\n",
    "\n",
    "**Hints:** \n",
    "- Read this [tutorial on type hints](https://pyrefly.org/en/docs/python-typing-for-beginners/).\n",
    "- Try running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca76cc-08e7-4cdb-aea8-9f88051779de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that ignores type hints\n",
    "hw1.add_str(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bcc58-c2cd-4d02-a27f-e1d897eaaedf",
   "metadata": {},
   "source": [
    "**Important:** For all coding problems on all assignments, you are expected to comply with the type hints provided to you in order to receive full credit.\n",
    "\n",
    "### Problem 1d: Understand Dict Methods (Written, 1 Point)\n",
    "\n",
    "A `dict` is a data type that is like a `list`, except that each item has a _key_ (i.e., a name) rather than a position. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6eed08-b09c-43a8-9392-f988877927e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'a': 1, 'b': 2, 'c': 5}\n",
      "{'a': 1, 'b': 2, 'c': 5, 'd': 10}\n"
     ]
    }
   ],
   "source": [
    "# Create a dict\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "\n",
    "# Get item \"b\"\n",
    "print(d[\"b\"])\n",
    "\n",
    "# Modify item \"c\"\n",
    "d[\"c\"] = 5\n",
    "print(d)\n",
    "\n",
    "# Add a new item with key \"d\"\n",
    "d[\"d\"] = 10\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608384f-d940-4336-b67c-e70ed648e7a6",
   "metadata": {},
   "source": [
    "Each `dict` comes with the functions `keys`, `values`, and `items`. Functions that come with an object of a certain type are called _methods_. What do these methods do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebab24d-c3a9-461f-8cd1-76a62c4578a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b', 'c', 'd'])\n",
      "dict_values([1, 2, 5, 10])\n",
      "dict_items([('a', 1), ('b', 2), ('c', 5), ('d', 10)])\n"
     ]
    }
   ],
   "source": [
    "print(d.keys())\n",
    "print(d.values())\n",
    "print(d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408dee7-426b-4304-a910-87b7a77773c3",
   "metadata": {},
   "source": [
    "What happens if you cast a `dict` to a `list` or a `set`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcad98c-b0ed-421d-86dd-f69a4b779850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bda800-bdd3-4ab1-b1ad-6e34148be7db",
   "metadata": {},
   "source": [
    "### Problem 1e: Practice Dict Comprehension (Code, 1 Point)\n",
    "\n",
    "Recall from class, and from [Chapter 1, Subsection 4.2 of the textbook](https://www.nltk.org/book/ch01.html), that we can build `list`s and `set`s from other `list`s and `set`s using _comprehension_. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808dd2e7-7735-462f-9050-332cdb2f8b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 4, 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 1, 2, 3, 5]\n",
    "{i + 1 for i in x}  # The set containing 1 plus each item in x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a56eeb-d01d-4c9c-9ed0-f2aad17e07ae",
   "metadata": {},
   "source": [
    "Comprehension can also be applied to `dict`s. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780a86b9-d1c0-44ae-a635-a6348159db24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 3, 'c': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "{k: v + 1 for k, v in d.items()}  # The dict containing 1 plus each item in d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37089f-a78c-4a43-8d2e-1cfa679a3ecd",
   "metadata": {},
   "source": [
    "Using comprehension, please implement the function `swap_keys_values` in the `hw1` module, which takes a `dict` as input and returns a new `dict` that maps each of the values in the original `dict` to its corresponding key. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c0c8b02-f2d6-46be-b856-75a32c9e8f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c'}\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "e = hw1.swap_keys_values(d)\n",
    "print(e)\n",
    "print(e[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f76c5-88dc-4055-8b29-416b42080762",
   "metadata": {},
   "source": [
    "### Problem 1f: Understand FreqDists (Written, 1 Point)\n",
    "\n",
    "NLTK has a data type called `FreqDist`. Please read [Chapter 1, Section 3 of the textbook](https://www.nltk.org/book/ch01.html#sec-computing-with-language-simple-statistics) to learn about `FreqDist`s.\n",
    "\n",
    "Just as a `Text` is really just a special kind of `list`, a `FreqDist` is really just a special kind of `dict`. A `FreqDist` is designed to map token types to the number of times they occur within a corpus. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336b392a-e546-4992-b4af-96a6378e0fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 60, 'of': 30, 'and': 20})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dict with counts for a hypothetical corpus\n",
    "counts = {\"the\": 60,   # \"the\" occurs 60 times in this corpus\n",
    "          \"of\": 30,    # \"of\"  occurs 30 times in this corpus\n",
    "          \"and\": 20}   # \"and\" occurs 20 times in this corpus\n",
    "\n",
    "# Turn the dict into a FreqDist\n",
    "FreqDist(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008809eb-ee8d-4e3c-b1eb-13619ad71fb4",
   "metadata": {},
   "source": [
    "A `FreqDist` can be _constructed_ (i.e., created) from a corpus, represented as a `list` or `Text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a36fc8-1e86-4d8e-835e-2a428c8e6174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2, 'The': 1, 'cat': 1, 'on': 1, 'boat': 1, 'smiled': 1, 'at': 1, 'dog': 1, '.': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"The\", \"cat\", \"on\", \"the\", \"boat\", \"smiled\", \"at\", \"the\", \"dog\", \".\"]\n",
    "FreqDist(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f1d43-c7d6-4413-892f-c5856d34c7e4",
   "metadata": {},
   "source": [
    "A `FreqDist` can also be obtained by calling the `vocab` method of a `Text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d9b03ed-ae17-4af4-9796-831988b64d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2, 'The': 1, 'cat': 1, 'on': 1, 'boat': 1, 'smiled': 1, 'at': 1, 'dog': 1, '.': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text(corpus).vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638304d-f288-4a05-93f4-6867e3347b43",
   "metadata": {},
   "source": [
    "What happens if you add two `FreqDist`s? For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51ac2ec-a6bc-47eb-9f8e-a481beffa21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 60, 'of': 30, 'and': 21, 'in': 3})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1 = FreqDist({\"the\": 60, \"of\": 30, \"and\": 20})\n",
    "dist2 = FreqDist({\"and\": 1, \"in\": 3})\n",
    "dist1 + dist2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cb7eb-4527-4452-95e9-2d7c9bc6ac8a",
   "metadata": {},
   "source": [
    "### Problem 1g: Unintended Uses of FreqDists (Written, 1 Point)\n",
    "\n",
    "Because `FreqDist`s are intended to contain counts of words within a corpus, most of the `FreqDist` methods are written under the assumption that a `FreqDist`s values will always be `int`s. However, we don't necessarily have to use `FreqDist`s for their intended purpose. Let's say you wanted a `FreqDist` to contain `float` values instead of `int` values. Is this allowed?\n",
    "\n",
    "**Hint:** Try creating a new `FreqDist` or modifying an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e7ced-034a-41b8-bb88-a557b2355136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you answer Problem 1g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f446b46-e809-4f70-8da5-dbb2492a2d49",
   "metadata": {},
   "source": [
    "### Problem 1h: Understand Mutable Objects (Written, 1 Point Extra Credit) \n",
    "\n",
    "In class, we saw that if you define one variable to be equal to another variable, then changing the first variable's value doesn't affect the second variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d143d6-79d2-4a49-bed3-a3e0d824aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=2, y=1\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "y = x\n",
    "x = 2\n",
    "print(f\"x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b41f06-c7df-4135-8a3f-ee722f43cfc2",
   "metadata": {},
   "source": [
    "Now, try running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d3f81-f229-4f6a-8dca-17dcf4c7f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [x, [4, 5, 6], x]\n",
    "print(f\"x={x}, y={y}\")\n",
    "\n",
    "x[0] = 7  # Change the value of x\n",
    "print(f\"x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda47598-a96c-406d-8b37-ebbb871234a2",
   "metadata": {},
   "source": [
    "Why does changing `x` change the value of `y`?\n",
    "\n",
    "**Hints:** \n",
    "- Try reading about [mutable vs. immutable data types](https://realpython.com/python-mutable-vs-immutable-types/).\n",
    "- Compare the above code with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd3da5-59e0-45b8-9a43-4e9213c18d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [x, [4, 5, 6], x]\n",
    "print(f\"x={x}, y={y}\")\n",
    "\n",
    "x = [7, 2, 3]  # Change the value of x\n",
    "print(f\"x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bb501-0661-4a1b-9484-c694b272e7c6",
   "metadata": {},
   "source": [
    "**Note:** Read this [tutorial](https://www.w3schools.com/python/python_string_formatting.asp) if you're curious about these fancy `print` statements.\n",
    "\n",
    "## Problem 2: Keyword Analysis of the ChatGPT Corpus (12 Points in Total)\n",
    "\n",
    "In this problem, you implement and execute a keyword analysis of the ChatGPT corpus. To do so, we need to understand exactly what it means for a token type to be a \"keyword.\" In class, we saw that \"delve\" is a keyword for the ChatGPT corpus, and we justified this by observing that \"delve\" is used somewhat often in the ChatGPT corpus, but almost never in the Wikipedia corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995cb508-17a4-411d-b636-7ee322bb87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wikipedia vs. ChatGPT corpus\n",
    "with open(\"wiki_vs_chatgpt_articles.p\", \"rb\") as f:\n",
    "    _dataset = pickle.load(f)\n",
    "    wiki_articles = _dataset[\"wiki\"]\n",
    "    chatgpt_articles = _dataset[\"chatgpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2e31b0-20e8-471f-9644-e4d51f68fcaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token type \"delve\" occurs...\n",
      "\t68 time(s) in the ChatGPT corpus and\n",
      "\t1 time(s) in the Wikipedia corpus.\n"
     ]
    }
   ],
   "source": [
    "# Compare the counts of \"delve\" in our two corpora\n",
    "t = \"delve\"\n",
    "print(f\"The token type \\\"{t}\\\" occurs...\\n\"\n",
    "      f\"\\t{chatgpt_articles.count(t)} time(s) in the ChatGPT corpus and\\n\"\n",
    "      f\"\\t{wiki_articles.count(t)} time(s) in the Wikipedia corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218b4f2-70ca-473f-9625-dac5e7edac10",
   "metadata": {},
   "source": [
    "The idea that you will pursue in this problem is that we can measure the _keyness_ of a token type within a corpus by comparing its frequency in that corpus with its frequency in a _reference corpus_. Once you have a method for measuring the keyness of a token type, you can identify keywords automatically by finding the token types with the highest keyness values.\n",
    "\n",
    "### Problem 2a: Understand Frequency Ratios (Written, 1 Point)\n",
    "\n",
    "To calculate keyness, we will use _frequency ratios_ as a _keyness metric_ [(Kilgarriff, 2009)](https://www.sketchengine.eu/wp-content/uploads/2015/04/2009-Simple-maths-for-keywords.pdf). The _relative frequency_ of a token type $w$ in a corpus $c$ is defined as:\n",
    "$$\\texttt{rel\\_freq}(w, c) = \\frac{c\\texttt{.count}(w)}{\\texttt{len}(c)}$$\n",
    "\n",
    "The _frequency ratio_ of a token type $w$ in _target corpus_ $c_1$ relative to _reference corpus_ $c_2$ is defined as:\n",
    "$$\\texttt{freq\\_ratio}(w, c_1, c_2) = \\frac{\\texttt{rel\\_freq}(w, c_1)}{\\texttt{rel\\_freq}(w, c_2)}$$\n",
    "\n",
    "What is the frequency ratio of \"delve\" in the ChatGPT corpus relative to the Wikipedia corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e26f2-e8b3-46de-9737-45ed6f1d9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you answer Problem 2a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129a58b-ee83-4ca1-bad3-00c01b80a79c",
   "metadata": {},
   "source": [
    "### Problem 2b: Determine Applicability of Frequency Ratios (Written, 2 Points)\n",
    "\n",
    "[Kilgarriff (2009, pp. 1–2)](https://www.sketchengine.eu/wp-content/uploads/2015/04/2009-Simple-maths-for-keywords.pdf) points out four potential problems with using frequency ratios as a keyness metric. The first two problems relate to whether frequency ratios are an appropriate keyness metric for the target and reference corpora.\n",
    "\n",
    "Please read Kilgarriff's paper, at least until you have read the first two of his four potential problems. Do you think frequency ratios are applicable to the ChatGPT and Wikipedia corpora? That is, do you think Kilgarriff's first and second problems are relevant to this assignment? Why or why not?\n",
    "\n",
    "### Problem 2c: Implement Smoothing (Code, 2 Points)\n",
    "\n",
    "Kilgarriff's third problem is that if $w$ does not appear in the reference corpus (i.e., if $c_2\\texttt{.count}(w) = 0$), then the formula for $\\texttt{freq\\_ratio}(w, c_1, c_2)$ will require you to divide by zero. To mitigate this problem, you will implement a popular tactic known as [_add-$k$ smoothing_](https://en.wikipedia.org/wiki/Additive_smoothing). When we apply add-$k$ smoothing to a corpus, we pretend that the corpus contains $k$ occurrences of each token type, in addition to what is actually in the text. The formula for relative frequency with add-$k$ smoothing is therefore:\n",
    "$$\\texttt{rel\\_freq}_k(w, c) = \\frac{c\\texttt{.count}(w) + k}{\\texttt{len}(c) + k\\cdot\\texttt{vocab\\_size}(c)}$$\n",
    "where $\\texttt{vocab\\_size}(c) = \\texttt{len}(\\texttt{set}(c))$.\n",
    "\n",
    "For this problem, please implement the functions `joint_vocab` and `smooth`. The `joint_vocab` function takes two `FreqDists` and returns a set containing all the token types represented across both `FreqDists`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99ba803e-05d7-4076-871c-91dedea141bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'in', 'of', 'the'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1 = FreqDist({\"the\": 60, \"of\": 30, \"and\": 20})\n",
    "dist2 = FreqDist({\"and\": 1, \"in\": 3})\n",
    "hw1.joint_vocab(dist1, dist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ac363-0915-43c8-ba77-1aa10c77d38b",
   "metadata": {},
   "source": [
    "The `smooth` function takes a `FreqDict` and applies add-$k$ smoothing to it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2dfd44c-3c2d-4223-bccc-20db13bc2e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'in': 4, 'and': 2, 'of': 1, 'the': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying add-1 smoothing\n",
    "vocab = hw1.joint_vocab(dist1, dist2)\n",
    "hw1.smooth(dist2, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abad04-4336-46a6-845e-561eae026bb0",
   "metadata": {},
   "source": [
    "`smooth` has an optional parameter `k`, with a default value of `1`, which represents the number of extra occurrences that will be added to the count of each token type in the `FreqDist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8123e1a0-c3e5-4042-9361-e9ddf1cc9612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'in': 13, 'and': 11, 'of': 10, 'the': 10})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying add-10 smoothing\n",
    "hw1.smooth(dist2, vocab, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acf326-c3cd-4926-8918-df2dfcaf8ac5",
   "metadata": {},
   "source": [
    "### Problem 2d: Normalize Distributions (Code, 1 Point)\n",
    "\n",
    "If `c` is a `Text`, then `c.vocab()` returns the _absolute frequency distribution_ of `c`; that is, `c.vocab()` maps each token type in `c` to its count in `c`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e536e214-f831-4cf6-a1dc-0b669ee9ea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2, 'The': 1, 'cat': 1, 'on': 1, 'boat': 1, 'smiled': 1, 'at': 1, 'dog': 1, '.': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [\"The\", \"cat\", \"on\", \"the\", \"boat\", \"smiled\", \"at\", \"the\", \"dog\", \".\"]\n",
    "Text(sent).vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c00414-156a-43c4-9a03-e4c22074240f",
   "metadata": {},
   "source": [
    "Please implement the function `normalize`, which converts an absolute frequency distribution into a _relative frequency distribution_ that maps each token type to its relative frequency in `c`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb73165e-ea13-434a-98ee-fcdf9d4ad3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 0.2, 'The': 0.1, 'cat': 0.1, 'on': 0.1, 'boat': 0.1, 'smiled': 0.1, 'at': 0.1, 'dog': 0.1, '.': 0.1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw1.normalize(Text(sent).vocab())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f9d15-0c08-4ad1-a111-d5eea6e59e44",
   "metadata": {},
   "source": [
    "### Problem 2e: Calculate Frequency Ratios (Code, 2 Points)\n",
    "\n",
    "Finally, please implement the function `freq_ratio`, which takes counts for a target corpus and a reference corpus and computes the frequency ratio for each token type in the joint vocabulary of both corpora with add-$k$ smoothing. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f0474a6-7add-4c8c-be1f-d08cd175eada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 4.280701754385965, 'of': 2.175438596491228, 'and': 0.7368421052631579, 'in': 0.017543859649122806})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dist = FreqDist({\"the\": 60, \"of\": 30, \"and\": 20})\n",
    "ref_dist = FreqDist({\"and\": 1, \"in\": 3})\n",
    "hw1.freq_ratio(target_dist, ref_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fc89f-1e77-48fc-bd7a-ff87d2bb2a46",
   "metadata": {},
   "source": [
    "`freq_ratio` has an optional parameter `k`, which determines the number of extra occurrences added to counts during add-$k$ smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d669eba2-46d9-4038-a114-defd489a59b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2.0533333333333332, 'of': 1.1733333333333333, 'and': 0.8, 'in': 0.22564102564102562})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw1.freq_ratio(target_dist, ref_dist, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27524b08-36af-4281-b20a-6b56f546b70e",
   "metadata": {},
   "source": [
    "**Hint:** Your code should call the other functions you implemented during the previous parts of this exercise.\n",
    "\n",
    "### Problem 2f: Identify ChatGPT Keywords (No Submission, 0 Points)\n",
    "\n",
    "Now, let's use your code to identify keywords from the ChatGPT corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a060a8-01a9-4c39-a8ab-434f2198c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stunning', 366.93441316302506),\n",
       " ('reminder', 254.4058933706665),\n",
       " ('breathtaking', 228.30163648567634),\n",
       " ('must-watch', 225.64696629398244),\n",
       " ('must-visit', 195.56070412145147),\n",
       " ('fascinating', 170.1201147843848),\n",
       " ('must-see', 160.16510156553264),\n",
       " ('resilience', 146.00686054316512),\n",
       " ('preparedness', 142.68852280354773),\n",
       " ('unforgettable', 141.58241022367525),\n",
       " ('well-maintained', 139.8126300958793),\n",
       " ('delves', 138.0428499680834),\n",
       " ('teamwork', 119.460158626226),\n",
       " ('thrilling', 114.00333656552185),\n",
       " ('delicious', 102.64724741216456)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ratios = hw1.freq_ratio(chatgpt_articles.vocab(), wiki_articles.vocab())\n",
    "freq_ratios.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9c1c3-cc53-4549-97f0-18e1a77801f7",
   "metadata": {},
   "source": [
    "If you run the above code cell after completing Problems 2c–e and get the same output, that is a good sign that your code is correct!\n",
    "\n",
    "### Problem 2g: Identify Wikipedia Keywords (Code and Written, 2 Points)\n",
    "\n",
    "To identify keywords from the Wikipedia corpus, we want to retrieve the token types with the _smallest_ frequency ratios. To do so, please implement the function `least_common`, which retrieves the items in a `FreqDist` with the smallest values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66e110b7-685e-48aa-a775-d1778b8ca11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nltk', 0), ('in', 10), ('and', 20)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = FreqDist({\"the\": 60, \"of\": 30, \"and\": 20, \"in\": 10, \"nltk\": 0})\n",
    "hw1.least_common(d, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff94fd-3604-4556-80e5-7dab20e28f3d",
   "metadata": {},
   "source": [
    "What are the top five keywords for the Wikipedia corpus (i.e., the five token types with the smallest frequency ratios, in ascending order of frequency ratio)?\n",
    "\n",
    "**Hints:** Try googling `how to sort a dict in python`.\n",
    "\n",
    "### Problem 2h: Limitations of Frequency Ratios (Written, 2 Points)\n",
    "\n",
    "According to [Kilgarriff's](https://www.sketchengine.eu/wp-content/uploads/2015/04/2009-Simple-maths-for-keywords.pdf) (2009) fourth problem, what is a limitation of using frequency ratios as a keyness metric? What solution does Kilgarriff propose for this problem?\n",
    "\n",
    "How do the keywords identified for the ChatGPT corpus change if you use add-1000 smoothing instead of add-1 smoothing? Are they less rare in the Wikipedia corpus? Support your answer by including a table of the following format. The first two columns have been filled in for you; please fill in the analogous information for the remaining two columns.\n",
    "\n",
    "|   | Keyword (k = 1) | Count in Wiki Corpus | Keyword (k = 1000) | Count in Wiki Corpus |\n",
    "|---|-----------------|----------------------|--------------------|----------------------|\n",
    "| 1 | stunning     | 2 | | |\n",
    "| 2 | reminder     | 3 | | |\n",
    "| 3 | breathtaking | 0 | | |\n",
    "| 4 | must-watch   | 0 | | |\n",
    "| 5 | must-visit   | 0 | | |\n",
    "| | **Average** | **1** | **Average** | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ca034-462f-4d6e-8209-4f0b21de4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you answer Problem 2h."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
